{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from preconditioners import settings\n",
    "from preconditioners.datasets import generate_true_parameter, CenteredLinearGaussianDataset, generate_true_parameter, generate_c\n",
    "from preconditioners.utils import MLP, SLP\n",
    "from preconditioners.optimizers import PrecondGD\n",
    "import preconditioners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in linear_kernel_variance_30102022.ipynb (and if it is not, it should be)\n",
    "\n",
    "from preconditioners.datasets import generate_c, generate_centered_linear_gaussian_data, generate_true_parameter, generate_W_star\n",
    "\n",
    "def kernel_variance_interpolator(features : np.ndarray, P : np.ndarray, F : np.ndarray, sigma2 : np.float64) -> np.float64:\n",
    "    ''' Given Nxp feature matrix {features}, pxp symmetric preconditioner P and pxp true covariance matrix F, and the signal to noise ratio, this function returns the variance component of the risk \n",
    "    of the interpolator which is the limit of PGD which uses preconditioner P.'''\n",
    "    assert features.shape[1] == P.shape[0] == P.shape[1] == F.shape[0] == F.shape[1]\n",
    "    assert abs(P - P.T).mean() < 1e-4, 'P must be symmetric.'\n",
    "\n",
    "    empirical_NTK = features.dot(P).dot(features.T)\n",
    "    empirical_NTK_inv = np.linalg.inv(empirical_NTK)\n",
    "    auxi_matrix = features.dot(P).dot(F).dot(P).dot(features.T)\n",
    "\n",
    "    return sigma2 * np.trace(empirical_NTK_inv.dot(auxi_matrix).dot(empirical_NTK_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted CheckEigenvalues class from src/preconditioners/eigenvalues/kernel_eigenvalues.py\n",
    "# with the linear gaussian dataset\n",
    "\n",
    "class Initializer:\n",
    "    def __init__(self,\n",
    "                width,\n",
    "                depth,\n",
    "                d,\n",
    "                lam,\n",
    "                train_size,\n",
    "                extra_size,\n",
    "                sigma2,\n",
    "                r2,\n",
    "                regime,\n",
    "                ro,\n",
    "                ):\n",
    "        # Network parameters\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.d = d\n",
    "        self.damping = lam * np.sqrt(self.d) if self.depth == 1 else lam * self.width\n",
    "\n",
    "        # Dataset parameters\n",
    "        self.train_size = train_size\n",
    "        self.extra_size = extra_size\n",
    "\n",
    "        w_star = generate_true_parameter(self.d, r2, m=np.eye(self.d))\n",
    "        c = generate_c(ro, regime=regime, d=self.d) if self.depth > 1 else generate_c(ro, regime=regime, d=self.d) * np.sqrt(self.d) # we don't need to multiply by sqrt(d) if d > 1 because there c is not the Fisher\n",
    "        dataset = CenteredLinearGaussianDataset(w_star, c, n=self.train_size + self.extra_size, d=self.d, sigma2=sigma2)\n",
    "\n",
    "        self.train_dataset, self.extra_dataset = random_split(dataset, [self.train_size, self.extra_size])\n",
    "        self.labeled_data = self.train_dataset[:][0].double().to(settings.DEVICE)\n",
    "        self.unlabeled_data = self.extra_dataset[:][0].double().to(settings.DEVICE)\n",
    "\n",
    "    def create_model(self):\n",
    "        std = 1/ np.sqrt(self.width)\n",
    "\n",
    "        # Create model and optimizer\n",
    "        if self.depth == 1:\n",
    "            self.model = SLP(in_channels=self.d).double().to(settings.DEVICE)\n",
    "        else:\n",
    "            self.model = MLP(in_channels=self.d, num_layers=self.depth, hidden_channels=self.width, std=std).double().to(settings.DEVICE)\n",
    "        self.optimizer = PrecondGD(self.model, lr=1e-2, labeled_data=self.labeled_data, unlabeled_data=self.unlabeled_data, verbose=False, damping=self.damping)\n",
    "\n",
    "    def get_features_and_p_inv(self):\n",
    "         self.create_model()\n",
    "         p_inv = self.optimizer._compute_p_inv()\n",
    "         grad = self.optimizer._compute_grad_of_data(self.labeled_data)\n",
    "         return grad, p_inv\n",
    "\n",
    "    def get_features_and_F(self):\n",
    "        self.create_model()\n",
    "        F = self.optimizer._compute_fisher()\n",
    "        grad = self.optimizer._compute_grad_of_data(self.labeled_data)\n",
    "        return grad, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0440, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## Test that I get the same results if the MLP is a linear network.\n",
    "\n",
    "N = 20\n",
    "N_extra = 30000\n",
    "sigma2 = 2\n",
    "ro = 0.9\n",
    "n_ds = 10\n",
    "n_lams = 10\n",
    "ds = [int(x) for x in np.linspace(2*N,65*N,n_ds)]\n",
    "ams = np.linspace(0.1,10,n_lams)\n",
    "lams = np.logspace(0, -3, num=n_lams, endpoint=True, base=10.0)\n",
    "\n",
    "d = 100\n",
    "lam = 0.1\n",
    "\n",
    "# linear\n",
    "np.random.seed(0)\n",
    "damping = lam * np.sqrt(d)\n",
    "c = np.sqrt(d) * generate_c(ro=ro, regime='autoregressive', d=d)\n",
    "X = np.random.multivariate_normal(mean=np.zeros(d), cov=c, size=N)\n",
    "#P_damped = np.linalg.inv(c + damping*np.eye(d))\n",
    "P_ngd = np.linalg.inv(c)\n",
    "\n",
    "# get it through the initializer\n",
    "i = Initializer(width = 1,\n",
    "                depth = 1,\n",
    "                d = d,\n",
    "                lam = lam,\n",
    "                train_size = N,\n",
    "                extra_size = N_extra,\n",
    "                sigma2 = sigma2,\n",
    "                r2 = 1,\n",
    "                regime = 'autoregressive',\n",
    "                ro = ro)\n",
    "\n",
    "grad, F = i.get_features_and_F()\n",
    "#grad, F_inv = i.get_features_and_p_inv()\n",
    "\n",
    "print(abs(F-c).mean())\n",
    "#print(np.linalg.norm(F_inv - P_damped)/np.sqrt(F_inv.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0165,  9.0078,  8.1416],\n",
       "        [ 9.0078,  9.9632,  8.9948],\n",
       "        [ 8.1416,  8.9948, 10.0032]], dtype=torch.float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10. ,  9. ,  8.1],\n",
       "       [ 9. , 10. ,  9. ],\n",
       "       [ 8.1,  9. , 10. ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "\n",
    "# In the below, am I not changing the dimension of the data, instead of changing the dimension of the model?\n",
    "# Fix it.\n",
    "\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.721999263637377e-16"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(P_ngd - P_ngd.T).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.46415888, 0.21544347, 0.1       , 0.04641589,\n",
       "       0.02154435, 0.01      , 0.00464159, 0.00215443, 0.001     ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 of 16\n",
      "51\n",
      "iteration 2 of 16\n",
      "51\n",
      "iteration 3 of 16\n",
      "51\n",
      "iteration 4 of 16\n",
      "51\n",
      "iteration 5 of 16\n",
      "68\n",
      "iteration 6 of 16\n",
      "68\n",
      "iteration 7 of 16\n",
      "68\n",
      "iteration 8 of 16\n",
      "68\n",
      "iteration 9 of 16\n",
      "85\n",
      "iteration 10 of 16\n",
      "85\n",
      "iteration 11 of 16\n",
      "85\n",
      "iteration 12 of 16\n",
      "85\n",
      "iteration 13 of 16\n",
      "119\n",
      "iteration 14 of 16\n",
      "119\n",
      "iteration 15 of 16\n",
      "119\n",
      "iteration 16 of 16\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "N_extra = 30000\n",
    "d = 15\n",
    "sigma2 = 2\n",
    "ro = 0.9\n",
    "n_ns = 4\n",
    "n_lams = 4\n",
    "variances_damped = np.zeros((n_ns,n_lams))\n",
    "variances_ngd = np.zeros((n_ns,n_lams))\n",
    "variances_diff = np.zeros((n_ns,n_lams))    \n",
    "largest_eigval_F_div_n = np.zeros((n_ns,n_lams))\n",
    "\n",
    "ns = [int(x) for x in np.linspace(int(np.sqrt(1.5*N)),int(np.sqrt(6*N)),n_ns)]\n",
    "ps = []\n",
    "lams = np.logspace(0, -2, num=n_lams, endpoint=True, base=10.0)\n",
    "dampings = []\n",
    "\n",
    "k = 0\n",
    "for i in range(n_ns):\n",
    "    for j in range(n_lams):\n",
    "        k = k+1\n",
    "        print(f'iteration {k} of {n_ns*n_lams}')\n",
    "        n = ns[i]\n",
    "        lam = lams[j]\n",
    "        damping = lam * n # TODO: check if multiplying by n is correct\n",
    "        dampings.append(damping)\n",
    "        \n",
    "        params = {\n",
    "            'width' : n,\n",
    "            'depth' : 2,\n",
    "            'd' : d,\n",
    "            'lam' : lam, # damping does not matter here if we are not using .get_features_and_p_inv()\n",
    "            'train_size' : N,\n",
    "            'extra_size' : N_extra,\n",
    "            'sigma2' : sigma2,\n",
    "            'r2' : 1,\n",
    "            'regime' : 'autoregressive',\n",
    "            'ro' : ro\n",
    "        }\n",
    "        # TODO: think about what is happening to lambda\n",
    "        ini = Initializer(**params)\n",
    "        features, F_extra = [x.numpy() for x in ini.get_features_and_F()]\n",
    "        p = F_extra.shape[0]\n",
    "        print(p)\n",
    "        ps.append(p)\n",
    "        #P_ngd = np.linalg.inv(F_extra + 1e-7 * np.eye(p)) # adding a small number to avoid singular matrix\n",
    "        P_ngd = np.linalg.inv(F_extra)\n",
    "        P_damped = np.linalg.inv(F_extra + damping * np.eye(p))\n",
    "        largest_eigval_F_div_n[i, j] = np.linalg.eigvalsh(F_extra)[-1]/n\n",
    "        \n",
    "        variances_damped[i, j] = kernel_variance_interpolator(features=features, P=P_damped, F=F_extra, sigma2=sigma2) \n",
    "        variances_ngd[i, j] = kernel_variance_interpolator(features=features, P=P_ngd, F=F_extra, sigma2=sigma2)\n",
    "        variances_diff = variances_damped - variances_ngd\n",
    "\n",
    "# choose only unique ps\n",
    "ps = np.unique(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 7]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 119)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_ngd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.919624890077172e-06"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(P_ngd - P_ngd.T).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.21544347, 0.04641589, 0.01      ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.93138389 16.54621801  1.62855125  2.92883684]\n",
      "[4.25162231 2.20376775 2.36819844 3.07939926]\n"
     ]
    }
   ],
   "source": [
    "print(variances_diff[0,:])\n",
    "print(variances_diff[-1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.93138389 3.24538369 2.06453211 4.25162231]\n",
      "[16.54621801  2.15879027  2.04423382  2.20376775]\n",
      "[1.62855125 1.5344186  2.34081939 2.36819844]\n"
     ]
    }
   ],
   "source": [
    "print(variances_diff[:,0])\n",
    "print(variances_diff[:,1])\n",
    "print(variances_diff[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51,  68,  85, 119])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(variances_diff, cmap='viridis', xticklabels=[round(x, 1) for x in lams], yticklabels=np.unique(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide each row of largest_eigval_F_div_n by the corresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31159753, 0.46564859, 0.79500419, 0.44552594],\n",
       "       [0.51493574, 0.19639807, 0.25373017, 0.34891709],\n",
       "       [0.43036858, 0.29826224, 0.29379363, 0.39070164],\n",
       "       [0.11932392, 0.17504401, 0.22715187, 0.12866675]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_eigval_F_div_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQnUlEQVR4nO3df4xlZ13H8fdnty0GqIWABtJdYdVFsgHCj81aoxHE1mwl2WpA3WJjEWQkskKsGktqipYQwg9LQtggG2wEAyzSRB3DYkn46Q9adggE2YWWYUnoNkD5UVpjsbs78/WPud1elp25d7p3nnvmzPuVPOmcc8997ndO0s88+5znnJuqQpLUxqZpFyBJG4mhK0kNGbqS1JChK0kNGbqS1NB5a/0Bl1x1o8sjBr51iafiQV990TunXUJnbH/vK6ZdQmd89U+vybn2sfjNp4z9P9qmJ9xxzp+3WmseupLU0iKLYx87jX/qG7qSemWhxg/daQSgoSupVxbp9jSeoSupV1YzvTANhq6kXjm5iumFaTB0JfXKgtMLktSOc7qS1NBCx5+caOhK6pVuz+gaupJ6xjldSWroZLcz19CV1C8LNH+cwqoYupJ6ZdGRriS140hXkhoydCWpoZPV7e9mMHQl9cpCx78Qx9CV1CuL5fSCJDXjnK4kNbTgnK4ktbPonK4ktXOiNk+7hBUZupJ6ZdE5XUlqxyVjktSQF9IkqaF1fyEtyS6gqupwkh3AbuDLVXVozauTpFVa6PjNESv+SUjyWuBtwDuSvAF4O/Ao4Nok163wvpkkc0nm7v7KpydasCSt5GSdN3YbJcnuJLcnmU9y7Vlef2uSzw/aHUm+P6rPUZ/6IuCZwCOAbwJbquq+JG8BbgNef7Y3VdUB4ADAJVfd2PGnW0rqk0ldSEuyGdgPXAYcBw4nma2qow8eU1V/MnT8HwPPGtXvqOpOVdVCVd0PfLWq7ht80A/o/ve/SdqAFipjtxF2AfNVdayqTgAHgStWOP5K4P2jOh0VuieSPHLw83Me3JnkIgxdSR20yKax2/BU6KDNDHV1MXDn0Pbxwb4fkeRJwDbgY6PqGzW98MtV9QBAVQ2H7PnA1aM6l6TWVrNkbHgq9BztBW6uqoVRB64Yug8G7ln2fwf4zsOrTZLWzsnJ3QZ8F7B1aHvLYN/Z7AVeOU6nrtOV1CsTvCPtMLA9yTaWwnYv8OIzD0ryVOCxwFhLtQxdSb0yqYeYV9WpJPuAW4DNwE1VdSTJDcBcVc0ODt0LHKyqsVZqGbqSemWSz14Y3AR26Ix915+x/Ver6dPQldQriz57QZLa8et6JKmhCa5eWBOGrqRecXpBkhryebqS1JBf1yNJDTnSlaSGJnVzxFoxdCX1iqsXJKmhdf8daZK0nnT9O9IMXUm94pyuJDXkzRGS1NBJQ1eS2nGkK0kNeUeaJDXk6gVJamjDTy986/KzfqHwhvTU1//PtEvojEv/6aXTLqEzfvznuj0yW29cMiZJDZ3a6CNdSWppw08vSFJLTi9IUkNdXzLW7XG4JK3SYmXsNkqS3UluTzKf5NpljvntJEeTHEnyvlF9OtKV1CuTml5IshnYD1wGHAcOJ5mtqqNDx2wHXgP8YlXdk+QnR/Vr6ErqlVOLE/sH/C5gvqqOASQ5CFwBHB065uXA/qq6B6Cq7h7VqdMLknplkYzdkswkmRtqM0NdXQzcObR9fLBv2FOApyT5zyS3Jtk9qj5HupJ6ZTXTC1V1ADhwDh93HrAdeB6wBfhUkqdX1fdXeoMk9cYEl4zdBWwd2t4y2DfsOHBbVZ0EvpbkDpZC+PBynTq9IKlXJrh64TCwPcm2JBcAe4HZM475Z5ZGuSR5PEvTDcdW6tSRrqReWZjQhbSqOpVkH3ALsBm4qaqOJLkBmKuq2cFrv5bkKLAA/HlVfXelfg1dSb0yyZsjquoQcOiMfdcP/VzANYM2FkNXUq94G7AkNVSGriS140hXkhpypCtJDS0sGrqS1EzXH+1o6ErqFacXJKkhL6RJUkNV065gZYaupF5xekGSGprUsxfWiqErqVe6Pr2w6j8JSd6zFoVI0iRUZew2DSuOdJOc+ezIAL+S5DEAVbVnmffNADMAj3vpb3Dh83ede6WSNIb1Pqe7haUvYXsXUCyF7k7gb1Z60/BXYGx77xs6PtiX1CddD5xR0ws7gc8C1wH3VtUngB9U1Ser6pNrXZwkrVYtZuw2DSuOdKtqEXhrkg8O/vutUe+RpGla79MLAFTVceC3krwAuG9tS5Kkh6/rqxdWNWqtqg8BH1qjWiTpnPVipCtJ64ahK0nt9Gp6QZK6blqrEsZl6Erql46PdLv9ZAhJWqVJ3gacZHeS25PMJ7n2LK+/JMm3k3x+0P5gVJ+OdCX1y4RGukk2A/uBy4DjwOEks1V19IxDP1BV+8bt15GupJ7JKtqKdgHzVXWsqk4AB4ErzrU6Q1dSvyyO35LMJJkbajNDPV0M3Dm0fXyw70wvTPKFJDcn2TqqPKcXJPXLKtbpDj+c62H6V+D9VfVAkj8E3g08f6U3ONKV1CtV47cR7gKGR65bBvuGPqu+W1UPDDbfBTxnVKeGrqR+qVW0lR0GtifZluQCYC/wQ88YT/LEoc09wJdGder0gqR+mdBtwFV1Ksk+4BZgM3BTVR1JcgMwV1WzwKuS7AFOAd8DXjKqX0NXUq9kgjdHVNUh4NAZ+64f+vk1wGtW06ehK6lfvA1Ykhrq+G3Ahq6kfjF0JakhQ1eSGvIh5pLUziRXL6wFQ1dSvxi6ktTOhh/pnvf1H1vrj1g37n3aBdMuoTO6/j9GSycumnYFPeOcriQ11PE/6IaupH4xdCWpnSxOu4KVGbqS+sWRriS10/WLtIaupH5x9YIkNeRIV5LacXpBkhpy9YIkteRIV5IaMnQlqZ2uz+lumnYBkrSRONKV1C+OdCWpnSyO30b2lexOcnuS+STXrnDcC5NUkp2j+jR0JfVLraKtIMlmYD9wObADuDLJjrMcdyHwauC2ccozdCX1Smr8NsIuYL6qjlXVCeAgcMVZjnsd8Ebg/8apz9CV1C+rGOkmmUkyN9Rmhnq6GLhzaPv4YN9pSZ4NbK2qD41bnhfSJPXKapaMVdUB4MDD+pxkE3Aj8JLVvM/QldQvk7sN+C5g69D2lsG+B10IPA34RBKAJwCzSfZU1dxynRq6knplgjdHHAa2J9nGUtjuBV784ItVdS/w+NOfm3wC+LOVAhec05XUNxNavVBVp4B9wC3Al4B/rKojSW5IsufhludIV1K/TPDmiKo6BBw6Y9/1yxz7vHH6NHQl9UrXn71g6Erqlz6FbpJfYmnB8Ber6iNrU5IkPXxdf4j5ihfSknxm6OeXA29naZnEa0fch3x6wfG9n/n0xIqVpJEmdCFtrYxavXD+0M8zwGVV9dfArwG/u9ybqupAVe2sqp0X7fqFCZQpSePJKto0jJpe2JTksSyFc6rq2wBV9b9JTq15dZK0Wut8Tvci4LMs/VGoJE+sqm8keTTT+0MhScta16sXqurJy7y0CPzmxKuRpHO1nkN3OVV1P/C1CdciSees66sXXKcrqV/6ONKVpK5a13O6krTuGLqS1I4jXUlqyQtpktSOI11JasnQlaR2Ut1OXUNXUr90O3MNXUn94pyuJDXkbcCS1JIjXUlqx+kFSWqp46E76ut6JGldSY3fRvaV7E5ye5L5s30vZJJXJPnvJJ9P8h9Jdozq09CV1CtZrLHbiv0km4H9wOXADuDKs4Tq+6rq6VX1TOBNwI2j6jN0JfXL5L4NeBcwX1XHquoEcBC44oc+quq+oc1HjdOrc7qSemWCS8YuBu4c2j4O/PyPfF7ySuAa4ALg+aM6daQrqV9WMdJNMpNkbqjNrPrjqvZX1c8AfwH85ajjHelK6pXVLBmrqgPAgWVevgvYOrS9ZbBvOQeBd4z6TEe6kvqlavy2ssPA9iTbklwA7AVmhw9Isn1o8wXAV0Z1uuYj3Sdf919r/RHrxnk/tWXaJXTGwhMeO+0SOuNR//LlaZfQHW849y4mNadbVaeS7ANuATYDN1XVkSQ3AHNVNQvsS3IpcBK4B7h6VL9OL0jqlUnekVZVh4BDZ+y7fujnV6+2T0NXUr/4PF1JasdnL0hSS4auJLXjSFeSWlroduoaupJ6xZGuJLXk6gVJaseRriS1ZOhKUjvxQpoktRPndCWpoW5nrqErqWcc6UpSO65ekKSWHOlKUjuuXpCklrqduYaupH5xyZgktWToSlJDE/piyrVi6ErqFacXJKmlxW4PdQ1dSf3S7cw1dCX1S9enFzZNuwBJmqiq8dsISXYnuT3JfJJrz/L6NUmOJvlCko8medKoPlcM3SSvSrJ1ZGWS1BUTCt0km4H9wOXADuDKJDvOOOxzwM6qegZwM/CmUeWNGum+Drgtyb8n+aMkPzGqw0GxM0nmkswdr2PjvEWSJmOhxm8r2wXMV9WxqjoBHASuGD6gqj5eVfcPNm8FtozqdFToHht08jrgOcDRJP+W5OokFy73pqo6UFU7q2rnlvz0qBokaWJSNX4bGiAO2sxQVxcDdw5tHx/sW87LgA+Pqm/UhbSqqkXgI8BHkpzP0lD7SuAtwFgjX0lqZhUX0qrqAHDgXD8yyVXATuC5o44dFboZ3qiqk8AsMJvkkQ+7QklaK4sTW71wFzB8TWvLYN8PSXIpcB3w3Kp6YFSno6YXfme5F4bmMSSpOya3euEwsD3JtiQXAHtZGnSeluRZwDuBPVV19zjlrTjSrao7xulEkjpjQut0q+pUkn3ALcBm4KaqOpLkBmCuqmaBNwOPBj6YBODrVbVnpX69OUJSvyxM7pa0qjoEHDpj3/VDP1+62j4NXUn9Ut2+D9jQldQvHb8N2NCV1C+TW72wJgxdSf3iSFeSGjJ0JamhhYVpV7AiQ1dSvzjSlaSGDF1JasjVC5LUTnlzhCQ1NMHbgNeCoSupX/wKdklqyAtpktROOdKVpIYc6UpSQy4Zk6R2ytuAJakh1+lKUjvl9IIkNdTxkW6q41f6JiXJTFUdmHYdXeC5eIjn4iGeizY2TbuAhmamXUCHeC4e4rl4iOeigY0UupI0dYauJDW0kULXuaqHeC4e4rl4iOeigQ1zIU2SumAjjXQlaeoMXUlqqFehm+SmJHcn+eIyryfJ25LMJ/lCkme3rrGVJLuT3D74Xa89y+vXJDk6OA8fTfKkadTZwhjn4hFJPjB4/bYkT55CmU14LqavV6EL/D2we4XXLwe2D9oM8I4GNTWXZDOwn6XfdwdwZZIdZxz2OWBnVT0DuBl4U9sq2xjzXLwMuKeqfhZ4K/DGtlW24bnohl6FblV9CvjeCodcAbynltwKPCbJE9tU19QuYL6qjlXVCeAgS7/7aVX18aq6f7B5K7ClcY2tjDwXg+13D36+GfjVJGlYYyueiw7oVeiO4WLgzqHt44N9fbPa3/NlwIfXtKLpGedcnD6mqk4B9wKPa1JdW56LDvCBNxtckquAncBzp12LtBFstJHuXcDWoe0tg319M9bvmeRS4DpgT1U90Ki21sY5F6ePSXIecBHw3SbVteW56ICNFrqzwO8NVjFcAtxbVd+YdlFr4DCwPcm2JBcAe1n63U9L8izgnSwF7t1TqLGVkedisH314OcXAR+rft415LnogF5NLyR5P/A84PFJjgOvBc4HqKq/BQ4Bvw7MA/cDvz+dStdWVZ1Ksg+4BdgM3FRVR5LcAMxV1SzwZuDRwAcH10m+XlV7plb0GhnzXPwd8A9J5lm6ELt3ehWvHc9FN3gbsCQ1tNGmFyRpqgxdSWrI0JWkhgxdSWrI0JWkhgxdSWrI0JWkhv4fOHj6H8RzjnEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(largest_eigval_F_div_n, cmap='viridis', xticklabels=[round(x, 1) for x in lams], yticklabels=ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "#######################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Triple check that we are computing the inverse well now and that we were doing it wrong before. Because the tests were passing before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.07106781, 6.36396103, 5.72756493],\n",
       "       [6.36396103, 7.07106781, 6.36396103],\n",
       "       [5.72756493, 6.36396103, 7.07106781]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.77817459, 6.36396103, 5.72756493],\n",
       "       [6.36396103, 7.77817459, 6.36396103],\n",
       "       [5.72756493, 6.36396103, 7.77817459]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c + damping*np.eye(d))[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40672876, -0.26077797, -0.06749992],\n",
       "       [-0.26077797,  0.573929  , -0.21749976],\n",
       "       [-0.06749992, -0.21749976,  0.58513116]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(c+ damping*np.eye(d))[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0352, -0.0173, -0.0002],\n",
       "        [-0.0173,  0.0352, -0.0173],\n",
       "        [-0.0002, -0.0173,  0.0352]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cholesky_inverse(torch.from_numpy(c+ damping*np.eye(d)))[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1522, -0.1304, -0.0057],\n",
       "        [-0.1304,  0.2640, -0.1256],\n",
       "        [-0.0057, -0.1256,  0.2642]], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cholesky_inverse(torch.cholesky(torch.from_numpy(c+ damping*np.eye(d))))[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15224482, -0.13042363, -0.00565121],\n",
       "       [-0.13042363,  0.26397487, -0.1255824 ],\n",
       "       [-0.00565121, -0.1255824 ,  0.26418464]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(c+ damping*np.eye(d))[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15224482, -0.13042363, -0.00565121],\n",
       "       [-0.13042363,  0.26397487, -0.1255824 ],\n",
       "       [-0.00565121, -0.1255824 ,  0.26418464]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_damped[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.73584905e-03, -8.49996340e-04, -8.67206609e-06],\n",
       "       [-8.49996340e-04,  1.73288370e-03, -8.62042779e-04],\n",
       "       [-8.67206609e-06, -8.62042779e-04,  1.76788253e-03]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_inv.numpy()[:3,:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('preconditioners_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5754338c7b61426a7939cdf73e45c35457822703652978ce6bf9eb7755ad6b2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
