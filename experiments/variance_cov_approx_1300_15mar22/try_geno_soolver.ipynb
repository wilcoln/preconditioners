{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from preconditioners.utils import generate_c, generate_centered_gaussian_data\n",
    "from preconditioners.cov_approx.variance_cov_approx import *\n",
    "from sklearn.covariance import  GraphicalLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the run\n",
    "n_epochs = 100\n",
    "iter_per_epoch = 500\n",
    "tol = 0.00001\n",
    "n = 200\n",
    "d = 600\n",
    "sigma2 = 1\n",
    "ro = 0.5\n",
    "regime = 'autoregressive'\n",
    "regul_lambda = 0 # for log barrier use 0.001\n",
    "lr_start = 0.5\n",
    "lr_decay = 0.98\n",
    "\n",
    "params = {\n",
    "    'n_epochs' : n_epochs,\n",
    "    'iter_per_epoch' : iter_per_epoch,\n",
    "    'tol' : tol,\n",
    "    'n' : n,\n",
    "    'd' : d,\n",
    "    'sigma2' : sigma2,\n",
    "    'ro' : ro,\n",
    "    'regime' : regime,\n",
    "    'regul_lambda' : regul_lambda,\n",
    "    'lr_start' : lr_start,\n",
    "    'lr_decay' : lr_decay\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardoravkin/Dropbox/My Mac (Eduardâ€™s MacBook Pro)/Desktop/ml_research/PhD/preconditioners/src/preconditioners/utils.py:219: UserWarning: Warning, norms of datapoints are not sqrt(d)\n",
      "  warnings.warn('Warning, norms of datapoints are not sqrt(d)')\n"
     ]
    }
   ],
   "source": [
    "# generate data and initialization\n",
    "c = generate_c(ro=ro,\n",
    "                regime=regime,\n",
    "                n=n,\n",
    "                d=d\n",
    "                )\n",
    "w_star = np.random.multivariate_normal(mean=np.zeros(d), cov=np.eye(d))\n",
    "X, y, xi = generate_centered_gaussian_data(w_star,\n",
    "                                            c,\n",
    "                                            n=n,\n",
    "                                            d=d,\n",
    "                                            sigma2=sigma2,\n",
    "                                            fix_norm_of_x=False)\n",
    "\n",
    "# initialize C (cholesky), cov_inv, regul_lambda and learning rate\n",
    "# is this a good way to initialize?\n",
    "cov_empir = X.T.dot(X) / n\n",
    "cov_inv = np.linalg.inv(cov_empir + 0.1 * np.eye(d))\n",
    "C = scipy.linalg.cholesky(cov_inv) + 0.5 * generate_c(ro=0.2,\n",
    "                                                        regime='autoregressive',\n",
    "                                                        n=n,\n",
    "                                                        d=d,\n",
    "                                                        )\n",
    "gl = GraphicalLasso(assume_centered=True, alpha=0.25, tol=1e-4).fit(X)\n",
    "cov_gl = gl.covariance_                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generating random instance\n",
      "solving ...\n",
      " Iteration   FunEvals     Step Length    Function Val   Proj Gradient\n",
      "         1          2               1     1.15831e+00     1.36363e-03\n",
      "         2          3               1     8.44208e-01     3.26045e-04\n",
      "         3          4               1     7.49832e-01     2.27151e-04\n",
      "         4          5               1     6.91029e-01     3.20838e-04\n",
      "         5          6               1     6.48583e-01     1.53114e-04\n",
      "         6          7               1     6.39214e-01     1.36215e-04\n",
      "         7          8               1     6.24823e-01     7.26546e-05\n",
      "         8          9               1     6.21432e-01     9.85542e-05\n",
      "         9         10               1     6.17449e-01     3.83805e-05\n",
      "        10         11               1     6.15737e-01     2.46499e-05\n",
      "        11         12               1     6.14062e-01     2.14058e-05\n",
      "        12         13               1     6.12853e-01     3.50055e-05\n",
      "        13         14               1     6.12003e-01     1.67870e-05\n",
      "        14         15               1     6.11670e-01     8.12877e-06\n",
      "solving took 3.097 sec\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample code automatically generated on 2022-03-15 12:54:45\n",
    "\n",
    "by geno from www.geno-project.org\n",
    "\n",
    "from input\n",
    "\n",
    "parameters\n",
    "  matrix B symmetric\n",
    "  matrix X\n",
    "variables\n",
    "  matrix C\n",
    "min\n",
    "  tr(inv(X*C*C'*X')*X*C*C'*B*C*C'*X'*inv(X*C*C'*X'))\n",
    "\n",
    "\n",
    "The generated code is provided \"as is\" without warranty of any kind.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "from math import inf\n",
    "from timeit import default_timer as timer\n",
    "try:\n",
    "    from genosolver import minimize, check_version\n",
    "    USE_GENO_SOLVER = True\n",
    "except ImportError:\n",
    "    from scipy.optimize import minimize\n",
    "    USE_GENO_SOLVER = False\n",
    "    WRN = 'WARNING: GENO solver not installed. Using SciPy solver instead.\\n' + \\\n",
    "          'Run:     pip install genosolver'\n",
    "    print('*' * 63)\n",
    "    print(WRN)\n",
    "    print('*' * 63)\n",
    "\n",
    "\n",
    "\n",
    "class GenoNLP:\n",
    "    def __init__(self, B, X, CInit, np):\n",
    "        self.np = np\n",
    "        self.B = B\n",
    "        self.X = X\n",
    "        self.CInit = CInit\n",
    "        assert isinstance(B, self.np.ndarray)\n",
    "        dim = B.shape\n",
    "        assert len(dim) == 2\n",
    "        self.B_rows = dim[0]\n",
    "        self.B_cols = dim[1]\n",
    "        assert isinstance(X, self.np.ndarray)\n",
    "        dim = X.shape\n",
    "        assert len(dim) == 2\n",
    "        self.X_rows = dim[0]\n",
    "        self.X_cols = dim[1]\n",
    "        assert isinstance(CInit, self.np.ndarray)\n",
    "        dim = CInit.shape\n",
    "        assert len(dim) == 2\n",
    "        self.C_rows = dim[0]\n",
    "        self.C_cols = dim[1]\n",
    "        self.C_size = self.C_rows * self.C_cols\n",
    "        # the following dim assertions need to hold for this problem\n",
    "        assert self.B_rows == self.C_rows == self.B_cols == self.X_cols\n",
    "\n",
    "    def getLowerBounds(self):\n",
    "        bounds = []\n",
    "        bounds += [-inf] * self.C_size\n",
    "        return self.np.array(bounds)\n",
    "\n",
    "    def getUpperBounds(self):\n",
    "        bounds = []\n",
    "        bounds += [inf] * self.C_size\n",
    "        return self.np.array(bounds)\n",
    "\n",
    "    def getStartingPoint(self):\n",
    "        return self.CInit.reshape(-1)\n",
    "\n",
    "    def variables(self, _x):\n",
    "        C = _x\n",
    "        C = C.reshape(self.C_rows, self.C_cols)\n",
    "        return C\n",
    "\n",
    "    def fAndG(self, _x):\n",
    "        C = self.variables(_x)\n",
    "        T_0 = self.np.linalg.inv((((self.X).dot(C)).dot(C.T)).dot(self.X.T))\n",
    "        T_1 = (self.X.T).dot(T_0)\n",
    "        T_2 = ((((T_1).dot(T_0)).dot(self.X)).dot(C)).dot(C.T)\n",
    "        T_3 = ((T_2).dot(self.B.T)).dot(C)\n",
    "        T_4 = (((T_1).dot(self.X)).dot(C)).dot(C.T)\n",
    "        T_5 = ((T_2).dot(self.B)).dot(C)\n",
    "        f_ = self.np.trace(((((((((T_0).dot(self.X)).dot(C)).dot(C.T)).dot(self.B)).dot(C)).dot(C.T)).dot(self.X.T)).dot(T_0))\n",
    "        g_0 = (((((T_3 - ((((((T_3).dot(C.T)).dot(self.X.T)).dot(T_0)).dot(self.X)).dot(C) + ((((((((T_4).dot(self.B)).dot(C)).dot(C.T)).dot(self.X.T)).dot(T_0)).dot(T_0)).dot(self.X)).dot(C))) + (((((((self.B).dot(C)).dot(C.T)).dot(self.X.T)).dot(T_0)).dot(T_0)).dot(self.X)).dot(C)) + (((((((self.B.T).dot(C)).dot(C.T)).dot(self.X.T)).dot(T_0)).dot(T_0)).dot(self.X)).dot(C)) + T_5) - (((((((((T_4).dot(self.B.T)).dot(C)).dot(C.T)).dot(self.X.T)).dot(T_0)).dot(T_0)).dot(self.X)).dot(C) + (((((T_5).dot(C.T)).dot(self.X.T)).dot(T_0)).dot(self.X)).dot(C)))\n",
    "        g_ = g_0.reshape(-1)\n",
    "        return f_, g_\n",
    "\n",
    "def solve(B, X, CInit, np):\n",
    "    start = timer()\n",
    "    NLP = GenoNLP(B, X, CInit, np)\n",
    "    x0 = NLP.getStartingPoint()\n",
    "    lb = NLP.getLowerBounds()\n",
    "    ub = NLP.getUpperBounds()\n",
    "    # These are the standard solver options, they can be omitted.\n",
    "    options = {'eps_pg' : 1E-4,\n",
    "               'max_iter' : 3000,\n",
    "               'm' : 10,\n",
    "               'ls' : 0,\n",
    "               'verbose' : 10  # Set it to 0 to fully mute it.\n",
    "              }\n",
    "\n",
    "    if USE_GENO_SOLVER:\n",
    "        # Check if installed GENO solver version is sufficient.\n",
    "        check_version('0.1.0')\n",
    "        result = minimize(NLP.fAndG, x0, lb=lb, ub=ub, options=options, np=np)\n",
    "    else:\n",
    "        result = minimize(NLP.fAndG, x0, jac=True, method='SLSQP',\n",
    "                          bounds=list(zip(lb, ub)))\n",
    "\n",
    "    # assemble solution and map back to original problem\n",
    "    C = NLP.variables(result.x)\n",
    "    elapsed = timer() - start\n",
    "    print('solving took %.3f sec' % elapsed)\n",
    "    return result, C\n",
    "\n",
    "def generateRandomData(np):\n",
    "    np.random.seed(0)\n",
    "    B = np.random.randn(3, 3)\n",
    "    B = 0.5 * (B + B.T)  # make it symmetric\n",
    "    X = np.random.randn(3, 3)\n",
    "    CInit = np.random.randn(3, 3)\n",
    "    return B, X, CInit\n",
    "import numpy as np\n",
    "# import cupy as np  # uncomment this for GPU usage\n",
    "print('\\ngenerating random instance')\n",
    "print('solving ...')\n",
    "\n",
    "result, C = solve(B = cov_gl, X=X, CInit = C, np=np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 5.00000000e-001, 2.50000000e-001, ...,\n",
       "        1.92793589e-180, 9.63967946e-181, 4.81983973e-181],\n",
       "       [5.00000000e-001, 1.00000000e+000, 5.00000000e-001, ...,\n",
       "        3.85587178e-180, 1.92793589e-180, 9.63967946e-181],\n",
       "       [2.50000000e-001, 5.00000000e-001, 1.00000000e+000, ...,\n",
       "        7.71174357e-180, 3.85587178e-180, 1.92793589e-180],\n",
       "       ...,\n",
       "       [1.92793589e-180, 3.85587178e-180, 7.71174357e-180, ...,\n",
       "        1.00000000e+000, 5.00000000e-001, 2.50000000e-001],\n",
       "       [9.63967946e-181, 1.92793589e-180, 3.85587178e-180, ...,\n",
       "        5.00000000e-001, 1.00000000e+000, 5.00000000e-001],\n",
       "       [4.81983973e-181, 9.63967946e-181, 1.92793589e-180, ...,\n",
       "        2.50000000e-001, 5.00000000e-001, 1.00000000e+000]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33333333e+000, -6.66666667e-001,  0.00000000e+000, ...,\n",
       "         1.42695921e-196,  7.13479606e-197,  3.56739803e-197],\n",
       "       [-6.66666667e-001,  1.66666667e+000, -6.66666667e-001, ...,\n",
       "         0.00000000e+000,  0.00000000e+000,  0.00000000e+000],\n",
       "       [ 0.00000000e+000, -6.66666667e-001,  1.66666667e+000, ...,\n",
       "         0.00000000e+000,  0.00000000e+000,  0.00000000e+000],\n",
       "       ...,\n",
       "       [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000, ...,\n",
       "         1.66666667e+000, -6.66666667e-001,  0.00000000e+000],\n",
       "       [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000, ...,\n",
       "        -6.66666667e-001,  1.66666667e+000, -6.66666667e-001],\n",
       "       [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000, ...,\n",
       "         0.00000000e+000, -6.66666667e-001,  1.33333333e+000]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.07478227, -0.95379315, -0.22001497, ..., -0.02531749,\n",
       "        -0.06549614,  0.02220345],\n",
       "       [-0.95379315, 12.05211481, -0.56384782, ...,  0.14054591,\n",
       "        -0.31947221, -0.28560944],\n",
       "       [-0.22001497, -0.56384782, 11.30834085, ...,  0.21381768,\n",
       "        -0.08630743,  0.01988035],\n",
       "       ...,\n",
       "       [-0.02531749,  0.14054591,  0.21381768, ...,  6.74194824,\n",
       "        -0.15906229, -0.20055089],\n",
       "       [-0.06549614, -0.31947221, -0.08630743, ..., -0.15906229,\n",
       "         7.62410242,  0.41575278],\n",
       "       [ 0.02220345, -0.28560944,  0.01988035, ..., -0.20055089,\n",
       "         0.41575278,  6.82268864]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.dot(C.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14486927,  0.02841294,  0.0088292 , ...,  0.00064288,\n",
       "        -0.00437891,  0.0021436 ],\n",
       "       [ 0.02841294,  0.12823607,  0.02227632, ..., -0.00374597,\n",
       "         0.00444023,  0.00987692],\n",
       "       [ 0.0088292 ,  0.02227632,  0.1457132 , ..., -0.00663828,\n",
       "         0.00636386,  0.00811664],\n",
       "       ...,\n",
       "       [ 0.00064288, -0.00374597, -0.00663828, ...,  0.32714795,\n",
       "        -0.04527662,  0.01599243],\n",
       "       [-0.00437891,  0.00444023,  0.00636386, ..., -0.04527662,\n",
       "         0.34057363, -0.07437366],\n",
       "       [ 0.0021436 ,  0.00987692,  0.00811664, ...,  0.01599243,\n",
       "        -0.07437366,  0.36378445]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(C.dot(C.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99657215,  0.45318984,  0.2292486 , ...,  0.03951084,\n",
       "         0.03796301, -0.00983083],\n",
       "       [ 0.45318984,  0.90459603,  0.39294534, ...,  0.05133407,\n",
       "        -0.03751195, -0.08232292],\n",
       "       [ 0.2292486 ,  0.39294534,  1.03292845, ...,  0.06005381,\n",
       "         0.02383041, -0.01841494],\n",
       "       ...,\n",
       "       [ 0.03951084,  0.05133407,  0.06005381, ...,  1.05608581,\n",
       "         0.42146556,  0.07348599],\n",
       "       [ 0.03796301, -0.03751195,  0.02383041, ...,  0.42146556,\n",
       "         0.80505165,  0.38310836],\n",
       "       [-0.00983083, -0.08232292, -0.01841494, ...,  0.07348599,\n",
       "         0.38310836,  0.99342184]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_empir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = GraphicalLasso(assume_centered=True, alpha=0.25, tol=1e-4).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05160023, -0.23620984, -0.        , ..., -0.        ,\n",
       "        -0.        ,  0.        ],\n",
       "       [-0.23620984,  1.18323836, -0.15640393, ..., -0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.        , -0.15640393,  1.04905384, ..., -0.        ,\n",
       "        -0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.        , -0.        , -0.        , ...,  1.0356648 ,\n",
       "        -0.20889973, -0.        ],\n",
       "       [-0.        ,  0.        , -0.        , ..., -0.20889973,\n",
       "         1.31479151, -0.17020701],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.        ,\n",
       "        -0.17020701,  1.02942771]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl.precision_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.18284640660346\n",
      "28.496966698194242\n",
      "19.19023109169065\n",
      "28.256759270030322\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(C.dot(C.T) - np.linalg.inv(c)))\n",
    "print(np.linalg.norm(C.dot(C.T)/10 - np.linalg.inv(c)))\n",
    "print(np.linalg.norm(gl.precision_ - np.linalg.inv(c)))\n",
    "print(np.linalg.norm(np.eye(d) - np.linalg.inv(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.002045396212072\n",
      "12.898884270794829\n",
      "16.309506430300093\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(np.diag(C.dot(C.T)/10) - np.diag(np.linalg.inv(c))))\n",
    "print(np.linalg.norm(np.diag(gl.precision_) - np.diag(np.linalg.inv(c))))\n",
    "print(np.linalg.norm(np.diag(np.eye(d)) - np.diag(np.linalg.inv(c))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.05160023 1.18323836 1.04905384 1.05717924 1.11796397 1.43840685\n",
      " 1.06769923 1.10150795 1.23079599 1.24661016]\n",
      "[2.07478227 3.05211481 2.30834085 2.21405823 2.57720359 4.53697898\n",
      " 1.93674428 2.25396307 2.9797089  3.47013248]\n",
      "[1.33333333 1.66666667 1.66666667 1.66666667 1.66666667 1.66666667\n",
      " 1.66666667 1.66666667 1.66666667 1.66666667]\n"
     ]
    }
   ],
   "source": [
    "print(np.diag(gl.precision_)[:10])\n",
    "print(np.diag(C.dot(C.T)-9)[:10])\n",
    "print(np.diag(np.linalg.inv(c))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix estimated\n",
      "empirical approximation computed\n"
     ]
    }
   ],
   "source": [
    "from neurips_code.utils import *\n",
    "from neurips_code.predicted_risk import *\n",
    "from neurips_code.Regressor import LinearRegressor\n",
    "\n",
    "c_e = generate_c_empir(X, empir='gl', alpha=0.25)\n",
    "m = np.eye(d)\n",
    "snr = 1\n",
    "include_best_achievable_empirical = True\n",
    "print('covariance matrix estimated')\n",
    "\n",
    "# initialize models\n",
    "reg_2 = LinearRegressor()\n",
    "reg_c = LinearRegressor()\n",
    "reg_ce = LinearRegressor()\n",
    "\n",
    "# generate predictors\n",
    "# matrix specifies which mirror descent we are using (GD if None)\n",
    "reg_2.fit(X, y, matrix = None)\n",
    "reg_c.fit(X, y, matrix = c)\n",
    "reg_ce.fit(X, y, matrix = c_e)\n",
    "\n",
    "w_a = compute_best_achievable_interpolator(X, y, c, m, snr)\n",
    "reg_a = LinearRegressor(init = w_a)\n",
    "\n",
    "if include_best_achievable_empirical:\n",
    "    w_ae = compute_best_achievable_interpolator(X, y, c = c_e, m = np.eye(d), snr = 1, crossval_param = 10)\n",
    "    reg_ae = LinearRegressor(init = w_ae)\n",
    "    print('empirical approximation computed')\n",
    "\n",
    "# best possible linear predictor\n",
    "c_mhalf = np.linalg.inv(scipy.linalg.sqrtm(c)) # inverse square root of the covariance matrix\n",
    "w_b = c_mhalf.dot( np.linalg.lstsq( X.dot(c_mhalf),  xi, rcond=None)[0] ) + w_star # best possible predictor\n",
    "reg_b = LinearRegressor(init = w_b)\n",
    "\n",
    "# calculate the expected risks\n",
    "risk_2 = calculate_risk(w_star, c, reg_2.w ) + sigma2\n",
    "risk_c = calculate_risk(w_star, c, reg_c.w) + sigma2\n",
    "risk_ce = calculate_risk(w_star, c, reg_ce.w) + sigma2\n",
    "risk_a = calculate_risk(w_star, c, reg_a.w) + sigma2\n",
    "if include_best_achievable_empirical:\n",
    "    risk_ae = calculate_risk(w_star, c, reg_ae.w) + sigma2\n",
    "risk_b = calculate_risk(w_star, c, reg_b.w) + sigma2\n",
    "\n",
    "risks = risk_2, risk_c, risk_ce, risk_a, risk_ae, risk_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322.5240568135326,\n",
       " 358.5945573373417,\n",
       " 329.43557275573266,\n",
       " 334.01221009068973,\n",
       " 326.09739570847603,\n",
       " 1.5212780213237065)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix estimated\n",
      "empirical approximation computed\n"
     ]
    }
   ],
   "source": [
    "from neurips_code.utils import *\n",
    "from neurips_code.predicted_risk import *\n",
    "from neurips_code.Regressor import LinearRegressor\n",
    "\n",
    "new_P = np.linalg.inv(C.dot(C.T))\n",
    "m = np.eye(d)\n",
    "snr = 1\n",
    "include_best_achievable_empirical = True\n",
    "print('covariance matrix estimated')\n",
    "\n",
    "# initialize models\n",
    "reg_2 = LinearRegressor()\n",
    "reg_c = LinearRegressor()\n",
    "reg_ce = LinearRegressor()\n",
    "\n",
    "# generate predictors\n",
    "# matrix specifies which mirror descent we are using (GD if None)\n",
    "reg_2.fit(X, y, matrix = None)\n",
    "reg_c.fit(X, y, matrix = c)\n",
    "reg_ce.fit(X, y, matrix = new_P)\n",
    "\n",
    "w_a = compute_best_achievable_interpolator(X, y, c, m, snr)\n",
    "reg_a = LinearRegressor(init = w_a)\n",
    "\n",
    "if include_best_achievable_empirical:\n",
    "    w_ae = compute_best_achievable_interpolator(X, y, c = new_P, m = np.eye(d), snr = 1, crossval_param = 10)\n",
    "    reg_ae = LinearRegressor(init = w_ae)\n",
    "    print('empirical approximation computed')\n",
    "\n",
    "# best possible linear predictor\n",
    "c_mhalf = np.linalg.inv(scipy.linalg.sqrtm(c)) # inverse square root of the covariance matrix\n",
    "w_b = c_mhalf.dot( np.linalg.lstsq( X.dot(c_mhalf),  xi, rcond=None)[0] ) + w_star # best possible predictor\n",
    "reg_b = LinearRegressor(init = w_b)\n",
    "\n",
    "# calculate the expected risks\n",
    "risk_2 = calculate_risk(w_star, c, reg_2.w ) + sigma2\n",
    "risk_c = calculate_risk(w_star, c, reg_c.w) + sigma2\n",
    "risk_ce = calculate_risk(w_star, c, reg_ce.w) + sigma2\n",
    "risk_a = calculate_risk(w_star, c, reg_a.w) + sigma2\n",
    "if include_best_achievable_empirical:\n",
    "    risk_ae = calculate_risk(w_star, c, reg_ae.w) + sigma2\n",
    "risk_b = calculate_risk(w_star, c, reg_b.w) + sigma2\n",
    "\n",
    "risks = risk_2, risk_c, risk_ce, risk_a, risk_ae, risk_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322.5240568135326,\n",
       " 358.5945573373417,\n",
       " 332.4241914222392,\n",
       " 334.01221009068973,\n",
       " 326.9068071389576,\n",
       " 1.5212780213237065)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d8cd6e4c5e5d135b57c7f4afa48b47bbab254644d54890f770c6527a3ab3f54"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('preconditioners')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
