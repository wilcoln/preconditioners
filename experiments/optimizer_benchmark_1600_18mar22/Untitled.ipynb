{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a96d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardoravkin/Desktop/ml_research/phd/preconditioners/src/preconditioners/utils.py:238: UserWarning: Warning, norms of datapoints are not sqrt(d)\n",
      "  warnings.warn('Warning, norms of datapoints are not sqrt(d)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise variance: 1.0\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 0.9588\n",
      "Epoch 20: Train loss: 0.8541\n",
      "Epoch 30: Train loss: 0.8024\n",
      "Epoch 40: Train loss: 0.7758\n",
      "Epoch 50: Train loss: 0.7560\n",
      "Epoch 60: Train loss: 0.7399\n",
      "Epoch 70: Train loss: 0.7253\n",
      "Epoch 80: Train loss: 0.7134\n",
      "Epoch 90: Train loss: 0.7028\n",
      "Epoch 100: Train loss: 0.6941\n",
      "Epoch 110: Train loss: 0.6870\n",
      "Epoch 120: Train loss: 0.6803\n",
      "Epoch 130: Train loss: 0.6742\n",
      "Epoch 140: Train loss: 0.6684\n",
      "Epoch 150: Train loss: 0.6637\n",
      "Epoch 160: Train loss: 0.6594\n",
      "Epoch 170: Train loss: 0.6554\n",
      "Epoch 180: Train loss: 0.6514\n",
      "Epoch 190: Train loss: 0.6477\n",
      "Epoch 200: Train loss: 0.6432\n",
      "Epoch 210: Train loss: 0.6392\n",
      "Epoch 220: Train loss: 0.6360\n",
      "Epoch 230: Train loss: 0.6324\n",
      "Epoch 240: Train loss: 0.6289\n",
      "Epoch 250: Train loss: 0.6259\n",
      "Epoch 260: Train loss: 0.6226\n",
      "Epoch 270: Train loss: 0.6197\n",
      "Epoch 280: Train loss: 0.6170\n",
      "Epoch 290: Train loss: 0.6138\n",
      "Epoch 300: Train loss: 0.6115\n",
      "Epoch 310: Train loss: 0.6089\n",
      "Epoch 320: Train loss: 0.6072\n",
      "Epoch 330: Train loss: 0.6056\n",
      "Epoch 340: Train loss: 0.6037\n",
      "Epoch 350: Train loss: 0.6024\n",
      "Epoch 360: Train loss: 0.6006\n",
      "Epoch 370: Train loss: 0.5998\n",
      "Epoch 380: Train loss: 0.5985\n",
      "Epoch 390: Train loss: 0.5983\n",
      "Epoch 400: Train loss: 0.6006\n",
      "Epoch 410: Train loss: 0.6060\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardoravkin/Desktop/ml_research/phd/preconditioners/src/preconditioners/optimizers.py:28: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "  p.data.add_(-group['lr'], d_p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise variance: 1.25\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 1.1725\n",
      "Epoch 20: Train loss: 0.8914\n",
      "Epoch 30: Train loss: 0.7785\n",
      "Epoch 40: Train loss: 0.7195\n",
      "Epoch 50: Train loss: 0.6832\n",
      "Epoch 60: Train loss: 0.6570\n",
      "Epoch 70: Train loss: 0.6410\n",
      "Epoch 80: Train loss: 0.6282\n",
      "Epoch 90: Train loss: 0.6154\n",
      "Epoch 100: Train loss: 0.6004\n",
      "Epoch 110: Train loss: 0.5890\n",
      "Epoch 120: Train loss: 0.5797\n",
      "Epoch 130: Train loss: 0.5726\n",
      "Epoch 140: Train loss: 0.5668\n",
      "Epoch 150: Train loss: 0.5607\n",
      "Epoch 160: Train loss: 0.5554\n",
      "Epoch 170: Train loss: 0.5504\n",
      "Epoch 180: Train loss: 0.5451\n",
      "Epoch 190: Train loss: 0.5412\n",
      "Epoch 200: Train loss: 0.5367\n",
      "Epoch 210: Train loss: 0.5324\n",
      "Epoch 220: Train loss: 0.5278\n",
      "Epoch 230: Train loss: 0.5236\n",
      "Epoch 240: Train loss: 0.5197\n",
      "Epoch 250: Train loss: 0.5160\n",
      "Epoch 260: Train loss: 0.5126\n",
      "Epoch 270: Train loss: 0.5085\n",
      "Epoch 280: Train loss: 0.5049\n",
      "Epoch 290: Train loss: 0.5017\n",
      "Epoch 300: Train loss: 0.4981\n",
      "Epoch 310: Train loss: 0.4932\n",
      "Epoch 320: Train loss: 0.4872\n",
      "Epoch 330: Train loss: 0.4829\n",
      "Epoch 340: Train loss: 0.4784\n",
      "Epoch 350: Train loss: 0.4741\n",
      "Epoch 360: Train loss: 0.4705\n",
      "Epoch 370: Train loss: 0.4671\n",
      "Epoch 380: Train loss: 0.4625\n",
      "Epoch 390: Train loss: 0.4589\n",
      "Epoch 400: Train loss: 0.4551\n",
      "Epoch 410: Train loss: 0.4519\n",
      "Epoch 420: Train loss: 0.4487\n",
      "Epoch 430: Train loss: 0.4451\n",
      "Epoch 440: Train loss: 0.4411\n",
      "Epoch 450: Train loss: 0.4386\n",
      "Epoch 460: Train loss: 0.4346\n",
      "Epoch 470: Train loss: 0.4310\n",
      "Epoch 480: Train loss: 0.4261\n",
      "Epoch 490: Train loss: 0.4230\n",
      "Epoch 500: Train loss: 0.4194\n",
      "Epoch 510: Train loss: 0.4162\n",
      "Epoch 520: Train loss: 0.4136\n",
      "Epoch 530: Train loss: 0.4113\n",
      "Epoch 540: Train loss: 0.4113\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n",
      "Noise variance: 1.5\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 1.7934\n",
      "Epoch 20: Train loss: 1.6568\n",
      "Epoch 30: Train loss: 1.6006\n",
      "Epoch 40: Train loss: 1.5614\n",
      "Epoch 50: Train loss: 1.5250\n",
      "Epoch 60: Train loss: 1.4968\n",
      "Epoch 70: Train loss: 1.4730\n",
      "Epoch 80: Train loss: 1.4554\n",
      "Epoch 90: Train loss: 1.4381\n",
      "Epoch 100: Train loss: 1.4206\n",
      "Epoch 110: Train loss: 1.4034\n",
      "Epoch 120: Train loss: 1.3879\n",
      "Epoch 130: Train loss: 1.3735\n",
      "Epoch 140: Train loss: 1.3589\n",
      "Epoch 150: Train loss: 1.3454\n",
      "Epoch 160: Train loss: 1.3324\n",
      "Epoch 170: Train loss: 1.3144\n",
      "Epoch 180: Train loss: 1.2959\n",
      "Epoch 190: Train loss: 1.2775\n",
      "Epoch 200: Train loss: 1.2548\n",
      "Epoch 210: Train loss: 1.2336\n",
      "Epoch 220: Train loss: 1.2158\n",
      "Epoch 230: Train loss: 1.2025\n",
      "Epoch 240: Train loss: 1.1894\n",
      "Epoch 250: Train loss: 1.1782\n",
      "Epoch 260: Train loss: 1.1666\n",
      "Epoch 270: Train loss: 1.1569\n",
      "Epoch 280: Train loss: 1.1476\n",
      "Epoch 290: Train loss: 1.1369\n",
      "Epoch 300: Train loss: 1.1314\n",
      "Epoch 310: Train loss: 1.1239\n",
      "Epoch 320: Train loss: 1.1500\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n",
      "Noise variance: 1.75\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 1.4545\n",
      "Epoch 20: Train loss: 1.3522\n",
      "Epoch 30: Train loss: 1.3188\n",
      "Epoch 40: Train loss: 1.2964\n",
      "Epoch 50: Train loss: 1.2790\n",
      "Epoch 60: Train loss: 1.2644\n",
      "Epoch 70: Train loss: 1.2508\n",
      "Epoch 80: Train loss: 1.2387\n",
      "Epoch 90: Train loss: 1.2279\n",
      "Epoch 100: Train loss: 1.2179\n",
      "Epoch 110: Train loss: 1.2062\n",
      "Epoch 120: Train loss: 1.1913\n",
      "Epoch 130: Train loss: 1.1790\n",
      "Epoch 140: Train loss: 1.1658\n",
      "Epoch 150: Train loss: 1.1516\n",
      "Epoch 160: Train loss: 1.1368\n",
      "Epoch 170: Train loss: 1.1219\n",
      "Epoch 180: Train loss: 1.1066\n",
      "Epoch 190: Train loss: 1.0908\n",
      "Epoch 200: Train loss: 1.0747\n",
      "Epoch 210: Train loss: 1.0582\n",
      "Epoch 220: Train loss: 1.0403\n",
      "Epoch 230: Train loss: 1.0219\n",
      "Epoch 240: Train loss: 1.0040\n",
      "Epoch 250: Train loss: 0.9873\n",
      "Epoch 260: Train loss: 0.9714\n",
      "Epoch 270: Train loss: 0.9549\n",
      "Epoch 280: Train loss: 0.9396\n",
      "Epoch 290: Train loss: 0.9248\n",
      "Epoch 300: Train loss: 0.9118\n",
      "Epoch 310: Train loss: 0.8969\n",
      "Epoch 320: Train loss: 0.8832\n",
      "Epoch 330: Train loss: 0.8695\n",
      "Epoch 340: Train loss: 0.8560\n",
      "Epoch 350: Train loss: 0.8436\n",
      "Epoch 360: Train loss: 0.8316\n",
      "Epoch 370: Train loss: 0.8267\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n",
      "Noise variance: 2.0\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 1.7290\n",
      "Epoch 20: Train loss: 1.5845\n",
      "Epoch 30: Train loss: 1.4983\n",
      "Epoch 40: Train loss: 1.4445\n",
      "Epoch 50: Train loss: 1.4092\n",
      "Epoch 60: Train loss: 1.3784\n",
      "Epoch 70: Train loss: 1.3484\n",
      "Epoch 80: Train loss: 1.3250\n",
      "Epoch 90: Train loss: 1.3046\n",
      "Epoch 100: Train loss: 1.2854\n",
      "Epoch 110: Train loss: 1.2672\n",
      "Epoch 120: Train loss: 1.2521\n",
      "Epoch 130: Train loss: 1.2379\n",
      "Epoch 140: Train loss: 1.2248\n",
      "Epoch 150: Train loss: 1.2124\n",
      "Epoch 160: Train loss: 1.2019\n",
      "Epoch 170: Train loss: 1.1935\n",
      "Epoch 180: Train loss: 1.1859\n",
      "Epoch 190: Train loss: 1.1775\n",
      "Epoch 200: Train loss: 1.1688\n",
      "Epoch 210: Train loss: 1.1604\n",
      "Epoch 220: Train loss: 1.1523\n",
      "Epoch 230: Train loss: 1.1444\n",
      "Epoch 240: Train loss: 1.1370\n",
      "Epoch 250: Train loss: 1.1292\n",
      "Epoch 260: Train loss: 1.1227\n",
      "Epoch 270: Train loss: 1.1168\n",
      "Epoch 280: Train loss: 1.1101\n",
      "Epoch 290: Train loss: 1.1022\n",
      "Epoch 300: Train loss: 1.0943\n",
      "Epoch 310: Train loss: 1.0849\n",
      "Epoch 320: Train loss: 1.0756\n",
      "Epoch 330: Train loss: 1.0657\n",
      "Epoch 340: Train loss: 1.0551\n",
      "Epoch 350: Train loss: 1.0432\n",
      "Epoch 360: Train loss: 1.0309\n",
      "Epoch 370: Train loss: 1.0177\n",
      "Epoch 380: Train loss: 1.0047\n",
      "Epoch 390: Train loss: 0.9925\n",
      "Epoch 400: Train loss: 0.9775\n",
      "Epoch 410: Train loss: 0.9658\n",
      "Epoch 420: Train loss: 0.9509\n",
      "Epoch 430: Train loss: 0.9436\n",
      "Epoch 440: Train loss: 0.9286\n",
      "Epoch 450: Train loss: 0.9373\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n",
      "Noise variance: 2.25\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 1.7566\n",
      "Epoch 20: Train loss: 1.7087\n",
      "Epoch 30: Train loss: 1.6720\n",
      "Epoch 40: Train loss: 1.6373\n",
      "Epoch 50: Train loss: 1.6033\n",
      "Epoch 60: Train loss: 1.5700\n",
      "Epoch 70: Train loss: 1.5338\n",
      "Epoch 80: Train loss: 1.5043\n",
      "Epoch 90: Train loss: 1.4729\n",
      "Epoch 100: Train loss: 1.4455\n",
      "Epoch 110: Train loss: 1.4182\n",
      "Epoch 120: Train loss: 1.3914\n",
      "Epoch 130: Train loss: 1.3650\n",
      "Epoch 140: Train loss: 1.3388\n",
      "Epoch 150: Train loss: 1.3108\n",
      "Epoch 160: Train loss: 1.2869\n",
      "Epoch 170: Train loss: 1.2631\n",
      "Epoch 180: Train loss: 1.2413\n",
      "Epoch 190: Train loss: 1.2191\n",
      "Epoch 200: Train loss: 1.1984\n",
      "Epoch 210: Train loss: 1.1788\n",
      "Epoch 220: Train loss: 1.1611\n",
      "Epoch 230: Train loss: 1.1454\n",
      "Epoch 240: Train loss: 1.1313\n",
      "Epoch 250: Train loss: 1.1174\n",
      "Epoch 260: Train loss: 1.1065\n",
      "Epoch 270: Train loss: 1.0988\n",
      "Epoch 280: Train loss: 1.0921\n",
      "Epoch 290: Train loss: 1.0814\n",
      "Epoch 300: Train loss: 1.0809\n",
      "Epoch 310: Train loss: 1.0733\n",
      "Epoch 320: Train loss: 1.0639\n",
      "Epoch 330: Train loss: 1.0656\n",
      "Epoch 340: Train loss: 1.0571\n",
      "Epoch 350: Train loss: 1.0543\n",
      "Epoch 360: Train loss: 1.0505\n",
      "Epoch 370: Train loss: 1.0473\n",
      "Epoch 380: Train loss: 1.0426\n",
      "Epoch 390: Train loss: 1.0369\n",
      "Epoch 400: Train loss: 1.0357\n",
      "Epoch 410: Train loss: 1.0367\n",
      "Epoch 420: Train loss: 1.0261\n",
      "Epoch 430: Train loss: 1.0278\n",
      "Epoch 440: Train loss: 1.0267\n",
      "Epoch 450: Train loss: 1.0224\n",
      "Epoch 460: Train loss: 1.0205\n",
      "Epoch 470: Train loss: 1.0227\n",
      "Epoch 480: Train loss: 1.0215\n",
      "Epoch 490: Train loss: 1.0211\n",
      "Epoch 500: Train loss: 1.0102\n",
      "Epoch 510: Train loss: 1.0307\n",
      "Epoch 520: Train loss: 1.0322\n",
      "Epoch 530: Train loss: 1.0319\n",
      "Epoch 540: Train loss: 1.0368\n",
      "Epoch 550: Train loss: 1.0136\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise variance: 2.5\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 2.4933\n",
      "Epoch 20: Train loss: 2.3220\n",
      "Epoch 30: Train loss: 2.2308\n",
      "Epoch 40: Train loss: 2.1595\n",
      "Epoch 50: Train loss: 2.1066\n",
      "Epoch 60: Train loss: 2.0618\n",
      "Epoch 70: Train loss: 2.0251\n",
      "Epoch 80: Train loss: 1.9948\n",
      "Epoch 90: Train loss: 1.9690\n",
      "Epoch 100: Train loss: 1.9472\n",
      "Epoch 110: Train loss: 1.9291\n",
      "Epoch 120: Train loss: 1.9076\n",
      "Epoch 130: Train loss: 1.8931\n",
      "Epoch 140: Train loss: 1.8826\n",
      "Epoch 150: Train loss: 1.8718\n",
      "Epoch 160: Train loss: 1.8594\n",
      "Epoch 170: Train loss: 1.8459\n",
      "Epoch 180: Train loss: 1.8343\n",
      "Epoch 190: Train loss: 1.8224\n",
      "Epoch 200: Train loss: 1.8111\n",
      "Epoch 210: Train loss: 1.7969\n",
      "Epoch 220: Train loss: 1.7845\n",
      "Epoch 230: Train loss: 1.7737\n",
      "Epoch 240: Train loss: 1.7630\n",
      "Epoch 250: Train loss: 1.7504\n",
      "Epoch 260: Train loss: 1.7402\n",
      "Epoch 270: Train loss: 1.7254\n",
      "Epoch 280: Train loss: 1.7138\n",
      "Epoch 290: Train loss: 1.6979\n",
      "Epoch 300: Train loss: 1.6912\n",
      "Epoch 310: Train loss: 1.6849\n",
      "Epoch 320: Train loss: 1.7403\n",
      "Epoch 330: Train loss: 1.8411\n",
      "Epoch 340: Train loss: 1.8763\n",
      "Epoch 350: Train loss: 1.8549\n",
      "Epoch 360: Train loss: 1.8394\n",
      "Epoch 370: Train loss: 1.8369\n",
      "Epoch 380: Train loss: 1.8077\n",
      "Epoch 390: Train loss: 1.8691\n",
      "Epoch 400: Train loss: 1.7932\n",
      "Epoch 410: Train loss: 1.8061\n",
      "Epoch 420: Train loss: 1.8649\n",
      "Epoch 430: Train loss: 1.8160\n",
      "Epoch 440: Train loss: 1.7954\n",
      "Epoch 450: Train loss: 1.7915\n",
      "Epoch 460: Train loss: 1.8529\n",
      "Epoch 470: Train loss: 1.8021\n",
      "Epoch 480: Train loss: 1.7761\n",
      "Epoch 490: Train loss: 1.7562\n",
      "Epoch 500: Train loss: 1.7796\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n",
      "Noise variance: 2.75\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 2.5693\n",
      "Epoch 20: Train loss: 2.4358\n",
      "Epoch 30: Train loss: 2.3520\n",
      "Epoch 40: Train loss: 2.2883\n",
      "Epoch 50: Train loss: 2.2407\n",
      "Epoch 60: Train loss: 2.2037\n",
      "Epoch 70: Train loss: 2.1700\n",
      "Epoch 80: Train loss: 2.1414\n",
      "Epoch 90: Train loss: 2.1112\n",
      "Epoch 100: Train loss: 2.0881\n",
      "Epoch 110: Train loss: 2.0674\n",
      "Epoch 120: Train loss: 2.0460\n",
      "Epoch 130: Train loss: 2.0247\n",
      "Epoch 140: Train loss: 2.0025\n",
      "Epoch 150: Train loss: 1.9797\n",
      "Epoch 160: Train loss: 1.9550\n",
      "Epoch 170: Train loss: 1.9280\n",
      "Epoch 180: Train loss: 1.8952\n",
      "Epoch 190: Train loss: 1.8648\n",
      "Epoch 200: Train loss: 1.8395\n",
      "Epoch 210: Train loss: 1.8273\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n",
      "Noise variance: 3.0\n",
      "\n",
      "\n",
      "Optimizer: GradientDescent\n",
      "Epoch 10: Train loss: 2.5399\n",
      "Epoch 20: Train loss: 2.2600\n",
      "Epoch 30: Train loss: 2.0970\n",
      "Epoch 40: Train loss: 1.9393\n",
      "Epoch 50: Train loss: 1.8407\n",
      "Epoch 60: Train loss: 1.7731\n",
      "Epoch 70: Train loss: 1.7231\n",
      "Epoch 80: Train loss: 1.6851\n",
      "Epoch 90: Train loss: 1.6529\n",
      "Epoch 100: Train loss: 1.6266\n",
      "Epoch 110: Train loss: 1.6090\n",
      "Epoch 120: Train loss: 1.5935\n",
      "Epoch 130: Train loss: 1.5783\n",
      "Epoch 140: Train loss: 1.5642\n",
      "Epoch 150: Train loss: 1.5455\n",
      "Epoch 160: Train loss: 1.5274\n",
      "Epoch 170: Train loss: 1.5128\n",
      "Epoch 180: Train loss: 1.5000\n",
      "Epoch 190: Train loss: 1.4875\n",
      "Epoch 200: Train loss: 1.4773\n",
      "Epoch 210: Train loss: 1.4673\n",
      "Epoch 220: Train loss: 1.4529\n",
      "Epoch 230: Train loss: 1.4395\n",
      "Epoch 240: Train loss: 1.4271\n",
      "Epoch 250: Train loss: 1.4142\n",
      "Epoch 260: Train loss: 1.3933\n",
      "Epoch 270: Train loss: 1.3673\n",
      "Epoch 280: Train loss: 1.3434\n",
      "Epoch 290: Train loss: 1.3229\n",
      "Epoch 300: Train loss: 1.3283\n",
      "\n",
      "\n",
      "Optimizer: PrecondGD\n",
      "MLP(\n",
      "  (in_layer): Linear(in_features=4, out_features=20, bias=False)\n",
      "  (hidden_layers): ModuleList()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=False)\n",
      ")\n",
      "=> We keep the following layers in PrecondGD. \n",
      "(0): Linear(in_features=4, out_features=20, bias=False)\n",
      "(1): Linear(in_features=20, out_features=1, bias=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run optimizer_benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b73edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('preconditioners')",
   "language": "python",
   "name": "python3102jvsc74a57bd02c2d541a5db7c05910ac06554e3a79dfe5bead4166f54a2f5ce9b07705345cc2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
